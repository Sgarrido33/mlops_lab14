name: MLOps Pipeline

on:
  workflow_dispatch:
    inputs:
      run_all:
        description: "Run all jobs"
        required: false
        default: "true"
  push:
    branches: [ main, master ]

jobs:
  data-processing:
    name: Data Processing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.11.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Process data
        run: |
          python src/data/run_processing.py --input data/raw/house_data.csv --output data/processed/cleaned_house_data.csv

      # Subimos el archivo limpio como artefacto para que el siguiente job lo pueda usar
      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/cleaned_house_data.csv

  feature-engineering:
    name: Feature Engineering
    needs: data-processing  # Este job espera a que termine el anterior
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.11.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # Creamos las carpetas necesarias
      - name: Create directories
        run: mkdir -p data/processed models/trained

      # Descargamos los datos limpios del paso anterior
      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed/

      - name: Engineer features
        run: |
          python src/features/engineer.py --input data/processed/cleaned_house_data.csv --output data/processed/featured_house_data.csv --preprocessor models/trained/preprocessor.pkl

      # AGREGA ESTO:
      - name: Upload feature engineering artifacts
        uses: actions/upload-artifact@v4
        with:
          name: featured-data
          path: |
            data/processed/featured_house_data.csv
            models/trained/preprocessor.pkl